model_lhood <- function(mod, dat) dmvnorm(dat, mod$mu, mod$Sigma)

#' Use trained models to classify observed formant values
#'
#' @param data Data frame with grouping columns used to generate models
#'   and F1,F2
#' @param models Data frame with column Vowels and list column `model`
#'   (as generated by `train_models`)
#'
#' @return Data frame with one row per data, with posterior probabilities
#'   in `posterior`, maximum-a-posteriori classification in `max_post`, and
#'   correctness in `correct`.
#'
#' @export
classify_mods <- function(data, models) {

  model_groups <- groups(models)

  model_lists <-
    models %>%
    do(models = purrr::set_names(.$model, .$Vowel))
    

 

  ## basically do it row-wise. slow but code is maybe clearer. and correct
  classifications <-
    data %>%
    left_join(model_lists) %>%
    ungroup() %>%
    mutate(f1f2 = map2(F1, F2, c),
           lhoods = map2(models, f1f2,
                         function(ms,d) map_dbl(ms,
                                                ~ model_lhood(., d)
                                                )
                         ),
           posterior = map(lhoods, ~ . / sum(.)),
           max_post = map_chr(posterior, ~ names(.)[which.max(.)]),
           correct = max_post == Vowel
           )

  ## [WIP] A more efficient implementation: get a matrix of all the data that
  ## draws on the same model, to take advantage of vectorization in `mvnorm`
  ## 
  ## data_grouped <-
  ##   data %>%
  ##   group_by_(.dots=model_groups) %>%
  ##   nest() %>%
  ##   mutate(true_categories = map(data, "Vowel"),
  ##          formants = map(data, ~ select(., F1, F2) %>% as.matrix())
  ##          )

  ## model_lists %>%
  ##   left_join(data_grouped) %>%
  ##   mutate(lhoods = list(map(models, ~ model_lhood(., formants)))) %>%
  ##   head(1) %$% lhoods %>% do.call(rbind, .) %>% str()
    

    
}
