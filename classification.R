model_lhood <- function(mod, dat) dmvnorm(dat, mod$mu, mod$Sigma)

#' Use trained models to classify observed formant values
#'
#' @param data Data frame with grouping columns used to generate models
#'   and F1,F2
#' @param models Data frame with column Vowels and list column `model`
#'   (as generated by `train_models`)
#' @param formants Names of formant columns in data. Optional, defaults to
#'   names in models.
#'
#' @return Data frame with one row per data maximum-a-posteriori classification
#' in `model_class`, and correctness in `correct`.
#'
#' @export
classify_mods <- function(data, models,
                          formants=names(models$model[[1]]$mu)) {

  model_groups <- groups(models)

  ## make a named list of vowel models for each group
  model_lists <-
    models %>%
    do(models = purrr::set_names(.$model, .$Vowel))

  ## A more efficient implementation than rowwise: get a matrix of all the data in
  ## a group that draws on the same models, to take advantage of vectorization
  ## in `mvnorm`
  ## 
  ## (THe downside is that unnest doesn't want to hold onto the token likelihoods...
  data %>%
    group_by_(.dots=model_groups) %>%
    nest() %>%
    left_join(model_lists) %>%
    mutate(formants = map(data, ~ select_(., .dots=formants) %>% as.matrix()),
           lhoods = map2(models, formants,
                         function(ms, f) map(ms, 
                                             ~ model_lhood(., f))),
           lhoods_mat = map(lhoods,
                            ~ do.call(rbind, .)),
           model_class = map(lhoods_mat, ~ rownames(.)[apply(., 2, which.max)])
           ## token_lhoods = map(lhoods_mat, ~ array_branch(., 2))
           )  %>%
    unnest(data, model_class) %>%
    mutate(correct = model_class == Vowel)
  
}
